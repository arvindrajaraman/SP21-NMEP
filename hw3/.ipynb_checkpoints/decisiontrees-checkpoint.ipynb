{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implent your own Decision Tree/Random Forest!\n",
    "\n",
    "\n",
    "In this python notebook, you will create a basic decision tree on pandas data, and train a classifier on the Iris dataset. Then, you will implement a type of bagging and create a random forest classifier!\n",
    "\n",
    "First, import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import and preview the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3  species\n",
       "0  5.1  3.5  1.4  0.2        0\n",
       "1  4.9  3.0  1.4  0.2        0\n",
       "2  4.7  3.2  1.3  0.2        0\n",
       "3  4.6  3.1  1.5  0.2        0\n",
       "4  5.0  3.6  1.4  0.2        0"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df['species'] = iris.target \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four features labeled 0, 1, 2, and 3. These stand for the length and the width of the sepals and petals, in centimeters. We want to use these four features to predict whether the species is one of three types of Iris plant, labeled 0, 1, or 2. \n",
    "\n",
    "Now, we split the dataset into training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "train = train.drop(['is_train'], axis = 1)\n",
    "test = test.drop(['is_train'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disorder (Splitting Metric)\n",
    "\n",
    "First, we want to implement some measure of disorder in a set of data.\n",
    "\n",
    "Implement either information gain or GINI impurity discussed in class. (for reference the equations are in 189 notes here https://www.eecs189.org/static/notes/n25.pdf) \n",
    "\n",
    "\n",
    "The argument `data` is a pandas dataframe containing the features and labels of several data points. We calculate disorder based on the labels, or the last column of the data. Note: make sure that you make this function work for different data (i.e. your function should work for data of different dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disorder(data):\n",
    "    val_counts = data['species'].value_counts()\n",
    "    gini = 1\n",
    "    for k, v in dict(val_counts).items():\n",
    "        gini -= (v / len(data)) ** 2\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a split function. This function takes in a dataset, and indices for a row and column. We then return two dataframes split on the `column`th feature. The left dataset should contain all of the data where the `column`th feature is greater or equal to the `column`th feature of the `row`th datapoint, and the right should contain the rest. Use the disorder metric you implemented in the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_row_column(data, row, column):\n",
    "    v = data[column].iloc[row]\n",
    "    left = data[data[column] >= v] #YOUR CODE HERE\n",
    "    right = data[data[column] < v] #YOUR CODE HERE\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to define our recursive tree class. During training, there are two cases for a node. If the data is all one label, the node is a leaf node, and we return this value during inference. If the data is not all the same label, we find the best split of the data by iterating through all of features and rows in the data. Use the split function defined above to find the best split.\n",
    "\n",
    "Inference takes in a row of a pandas dataframes and returns the predicted class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def train(self):\n",
    "        #Your code here\n",
    "        if len(self.data['species'].value_counts()) == 1:\n",
    "            self.is_leaf = True\n",
    "            self.value = self.data['species'].iloc[0]\n",
    "        elif all([len(self.data[self.data.columns[c]].value_counts()) == 1 for c in range(len(self.data.columns) - 1)]):\n",
    "            self.is_leaf = True\n",
    "            self.value = self.data['species'].mode()[0]\n",
    "        else:\n",
    "            self.is_leaf = False\n",
    "            best_c, best_cr, best_c_disorder_split = -1, -1, float('inf')\n",
    "            for c in range(len(self.data.columns) - 1):\n",
    "                col = self.data.columns[c]\n",
    "                best_r, best_r_disorder_split = -1, float('inf')\n",
    "                for r in range(len(self.data)):\n",
    "                    left, right = split_on_row_column(self.data, r, col)\n",
    "                    disorder_split = (len(left) / len(self.data)) * disorder(left) + (len(right) / len(self.data)) * disorder(right)\n",
    "                    if disorder_split < best_r_disorder_split:\n",
    "                        best_r, best_r_disorder_split = r, disorder_split\n",
    "                if best_r_disorder_split < best_c_disorder_split:\n",
    "                    best_c, best_cr, best_c_disorder_split = col, best_r, best_r_disorder_split\n",
    "            left, right = split_on_row_column(self.data, best_cr, best_c)\n",
    "            self.feature = best_c\n",
    "            self.v = self.data[best_c].iloc[best_cr]\n",
    "            self.left = Node(left)\n",
    "            self.left.train()\n",
    "            self.right = Node(right)\n",
    "            self.right.train()\n",
    "        \n",
    "    def inference(self, x):\n",
    "        if self.is_leaf:\n",
    "            return self.value\n",
    "        elif x[self.feature] >= self.v:\n",
    "            return self.left.inference(x)\n",
    "        else:\n",
    "            return self.right.inference(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize and train a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Node(train)\n",
    "tree.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we don't check the training accuracy here (why?). We now want to validate our tree on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117647058823529"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate(model, data):\n",
    "    ct = 0\n",
    "    corr = 0\n",
    "    for i in range(test.shape[0]):\n",
    "        data = test.iloc[i]\n",
    "        ct += 1\n",
    "        if model.inference(data) == data['species']:\n",
    "            corr += 1\n",
    "    return corr/ct\n",
    "\n",
    "validate(tree, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest!\n",
    "\n",
    "Now we will implement data bagging with a random forest! The set up is similar to a single tree. We pass in the data to the forest, along with hyperparameters `n`, `frac`, anbd `m`, which correspond to the number of trees, the fraction of the dataset to use in each bag, the number or percentage of random features (depending on your own implementation) selected at each possible split. Note that the difference between random forests and just bagging  is that random forests select a random subset of features per bag while bagging assumes all features are present in each sample. A good estimate for m in a dataset with `num_features` is m = sqrt(`num_features`). In the inference step we tally the number of votes from each decision tree and return the label with the most amount of votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forest:\n",
    "    def __init__(self, data, n, frac, m=2):\n",
    "        self.data = data\n",
    "        self.n = n\n",
    "        self.frac = frac\n",
    "        self.m = m\n",
    "    \n",
    "    def train(self):\n",
    "        self.trees = []\n",
    "        for i in range(self.n):\n",
    "            print('Training tree', i + 1)\n",
    "            data = self.data.sample(frac=self.frac, replace=True)\n",
    "            cols_to_drop = list(np.random.choice(len(self.data.columns) - 1, self.m, replace=False))\n",
    "            data.drop(columns=cols_to_drop, inplace=True)\n",
    "            tree = Node(data)\n",
    "            tree.train()\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def inference(self, x):\n",
    "        decisions = {}\n",
    "        for tree in self.trees:\n",
    "            decision = tree.inference(x)\n",
    "            if decision in decisions:\n",
    "                decisions[decision] += 1\n",
    "            else:\n",
    "                decisions[decision] = 1\n",
    "        return max(decisions, key=decisions.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and validate your forest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tree 1\n",
      "Training tree 2\n",
      "Training tree 3\n",
      "Training tree 4\n",
      "Training tree 5\n",
      "Training tree 6\n",
      "Training tree 7\n",
      "Training tree 8\n",
      "Training tree 9\n",
      "Training tree 10\n",
      "Training tree 11\n",
      "Training tree 12\n",
      "Training tree 13\n",
      "Training tree 14\n",
      "Training tree 15\n",
      "Training tree 16\n",
      "Training tree 17\n",
      "Training tree 18\n",
      "Training tree 19\n",
      "Training tree 20\n",
      "Training tree 21\n",
      "Training tree 22\n",
      "Training tree 23\n",
      "Training tree 24\n",
      "Training tree 25\n",
      "Training tree 26\n",
      "Training tree 27\n",
      "Training tree 28\n",
      "Training tree 29\n",
      "Training tree 30\n"
     ]
    }
   ],
   "source": [
    "forest = Forest(train, 30, .5)\n",
    "forest.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(forest, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
